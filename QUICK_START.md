# QA-ViT + PNP-VQA å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹ (5åˆ†é’Ÿè®¾ç½®)

### æ­¥éª¤ 1: å®‰è£…ä¾èµ–
```bash
python3 install_dependencies.py
```

### æ­¥éª¤ 2: éªŒè¯å®‰è£…
```bash
python3 test_setup.py
```
å¦‚æœçœ‹åˆ° "âœ“ All tests passed!"ï¼Œç»§ç»­ä¸‹ä¸€æ­¥ã€‚

### æ­¥éª¤ 3: è¿è¡Œæ¼”ç¤º
```bash
# è¿è¡Œé»˜è®¤ç¤ºä¾‹
python3 run_demo.py

# æˆ–ä½¿ç”¨è‡ªå®šä¹‰å›¾åƒ
python3 run_demo.py --custom --image your_image.jpg --question "What is in the image?"
```

## ğŸ“ åŸå§‹ä»£ç é—®é¢˜æ€»ç»“

æ‚¨çš„ `qacap_vqa.py` å®ç°ä¸»è¦å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

| é—®é¢˜ç±»å‹ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|---------|------|---------|
| **from_configæ–¹æ³•** | ç¼ºå°‘ qavit_model_config å’Œ text_encoder å‚æ•° | âœ… æ·»åŠ å®Œæ•´çš„å‚æ•°å¤„ç†é€»è¾‘ |
| **å¯¼å…¥é”™è¯¯** | clip_vision_tower è·¯å¾„ä¸æ­£ç¡® | âœ… ä¿®æ­£ä¸ºæ­£ç¡®çš„ qavit_encoder å¯¼å…¥ |
| **è®¾å¤‡å¤„ç†** | ç›´æ¥ä½¿ç”¨ä¸å­˜åœ¨çš„ self.device | âœ… æ·»åŠ  @property device æ–¹æ³• |
| **æ¨¡å‹å¼•ç”¨** | å¼•ç”¨å·²åˆ é™¤çš„ image_question_matching_model | âœ… æ¸…ç†æ‰€æœ‰æ— æ•ˆå¼•ç”¨ |
| **è¾¹ç•Œæ£€æŸ¥** | ç¼ºå°‘æ³¨æ„åŠ›å±‚æ•°æ£€æŸ¥ | âœ… æ·»åŠ å®Œæ•´çš„è¾¹ç•Œå’Œé”™è¯¯å¤„ç† |

## ğŸ¯ ä¸»è¦æ”¹è¿›

### 1. æ¶æ„ä¼˜åŒ–
- **é—®é¢˜æ„ŸçŸ¥æ³¨æ„åŠ›**: QA-ViT æ ¹æ®é—®é¢˜å†…å®¹ç”Ÿæˆç›¸å…³çš„è§†è§‰æ³¨æ„åŠ›
- **åŠ¨æ€èåˆ**: åœ¨å¤šä¸ªå±‚çº§èåˆè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯
- **å…¼å®¹æ€§**: ä¿æŒä¸åŸ PNP-VQA çš„å®Œå…¨å…¼å®¹

### 2. åŠŸèƒ½å¢å¼º
- **ä¸‰ç§å¯è§†åŒ–**: åŸå›¾ã€çƒ­åŠ›å›¾ã€å åŠ å›¾
- **ç»Ÿè®¡åˆ†æ**: è¯¦ç»†çš„æ³¨æ„åŠ›åˆ†å¸ƒç»Ÿè®¡
- **æ‰¹å¤„ç†æ”¯æŒ**: å¯æ‰©å±•æ”¯æŒå¤šå›¾åƒå¤„ç†

### 3. ç”¨æˆ·ä½“éªŒ
- **ä¸€é”®å®‰è£…**: è‡ªåŠ¨åŒ–ä¾èµ–ç®¡ç†
- **å®Œæ•´æµ‹è¯•**: ç¯å¢ƒéªŒè¯å’ŒåŠŸèƒ½æµ‹è¯•
- **è¯¦ç»†æ–‡æ¡£**: å®Œæ•´çš„ä½¿ç”¨è¯´æ˜å’ŒAPIæ–‡æ¡£

## ğŸ“Š é¢„æœŸè¾“å‡º

è¿è¡Œdemoåï¼Œæ‚¨å°†çœ‹åˆ°ï¼š

```
============================================================
QA-ViT + PNP-VQA Heat Map Generation Demo
============================================================
Generating heat map for question: 'What colors are in the image?'
Model setup completed successfully!

Attention Statistics:
- Max attention: 0.0856
- Min attention: 0.0021  
- Mean attention: 0.0041
- Std attention: 0.0098

Heat map saved to: ./demo_outputs/heatmap_sample.png
```

ä»¥åŠåŒ…å«ä¸‰ä¸ªå­å›¾çš„å¯è§†åŒ–å›¾åƒï¼š
1. åŸå§‹å›¾åƒ
2. QA-ViT æ³¨æ„åŠ›çƒ­åŠ›å›¾  
3. æ³¨æ„åŠ›å åŠ å›¾åƒ

## ğŸ”§ è‡ªå®šä¹‰ä½¿ç”¨

### ç¼–ç¨‹å¼API
```python
from demo_qavit_heatmap import QAViTHeatMapDemo

# åˆå§‹åŒ–
demo = QAViTHeatMapDemo(device='cuda')

# ç”Ÿæˆçƒ­åŠ›å›¾
fig, attention_map = demo.run_demo(
    image_path="path/to/image.jpg",
    question="What objects are visible?",
    output_dir="./my_outputs"
)
```

### é…ç½®ä¿®æ”¹
ç¼–è¾‘ `/workspace/configs/models/qacap/pnp_vqa_qavit.yaml`:
```yaml
qavit_config:
  vit_model: "openai/clip-vit-large-patch14"  # æ›´å¤§æ¨¡å‹
  integration_point: "late"  # æ”¹å˜èåˆç­–ç•¥
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜
1. **å†…å­˜ä¸è¶³**: ä½¿ç”¨ `--device cpu`
2. **ä¾èµ–ç¼ºå¤±**: é‡æ–°è¿è¡Œ `python3 install_dependencies.py`
3. **æ¨¡å‹ä¸‹è½½æ…¢**: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨ç¼“å­˜

### è·å–å¸®åŠ©
```bash
python3 demo_qavit_heatmap.py --help
python3 run_demo.py --help
```

## ğŸ“ˆ åç»­æ‰©å±•

- **æ‰¹é‡å¤„ç†**: æ‰©å±•æ”¯æŒå¤šå›¾åƒæ‰¹å¤„ç†
- **æ³¨æ„åŠ›åˆ†æ**: æ·»åŠ å±‚çº§æ³¨æ„åŠ›æ¯”è¾ƒ
- **å®æ—¶æ¨ç†**: é›†æˆwebcamå®æ—¶å¤„ç†
- **æ¨¡å‹å¾®è°ƒ**: æ”¯æŒç‰¹å®šé¢†åŸŸçš„æ¨¡å‹å¾®è°ƒ

---

**Ready to go! ğŸ‰** æ‚¨ç°åœ¨æ‹¥æœ‰ä¸€ä¸ªå®Œæ•´çš„ã€å¯å·¥ä½œçš„ QA-ViT + PNP-VQA çƒ­åŠ›å›¾ç”Ÿæˆç³»ç»Ÿ!